var documenterSearchIndex = {"docs":
[{"location":"Details/Interprecision_1/#Interprecision-Transfers:-Part-I","page":"Interprecision Transfers: Part I","title":"Interprecision Transfers: Part I","text":"","category":"section"},{"location":"Details/Interprecision_1/","page":"Interprecision Transfers: Part I","title":"Interprecision Transfers: Part I","text":"The discussion in this section is for the most useful case where high precision is Float64 and low precision is Float32. Things are different if low precision is Float16.","category":"page"},{"location":"Details/Interprecision_1/","page":"Interprecision Transfers: Part I","title":"Interprecision Transfers: Part I","text":"Recall that the default way to use the low precision factorization  is to copy r into low precision, scale it, perform the solve in  low precision, and then reverse the scaling and promote the  correction d. So if AF = lu(A32) is  the factorization object for the low precision factorization, then we compute d via","category":"page"},{"location":"Details/Interprecision_1/","page":"Interprecision Transfers: Part I","title":"Interprecision Transfers: Part I","text":"d = norm(r)* Float64.( AF\\ (Float32.(r / norm(r))))","category":"page"},{"location":"Details/Interprecision_1/","page":"Interprecision Transfers: Part I","title":"Interprecision Transfers: Part I","text":"We will refer to this approach as the low precision solve (LPS).  As we said earlier, if one simply does","category":"page"},{"location":"Details/Interprecision_1/","page":"Interprecision Transfers: Part I","title":"Interprecision Transfers: Part I","text":"d = AF\\r","category":"page"},{"location":"Details/Interprecision_1/","page":"Interprecision Transfers: Part I","title":"Interprecision Transfers: Part I","text":"the elements of the triangular matrices are promoted to double as the solves take place. We will refer to this as a mixed precision solve (MPS). In the table below we report timings from Julia's  BenchmarkTools package for double precision matrix vector multiply (MV64), single precision LU factorization (LU32) and three approaches for using the factors to solve a linear system. HPS is the time for a fully double precision triangular solved and MPS and LPS are the mixed precision solve and the fully low precision solve. IR will use a high precision matrix vector multiply to compute the residual and a solve to compute the correction for each iteration. The low precision factorization is done only once.","category":"page"},{"location":"Details/Interprecision_1/","page":"Interprecision Transfers: Part I","title":"Interprecision Transfers: Part I","text":"In this example A = I + 800 G(N) and we look at several values of N.","category":"page"},{"location":"Details/Interprecision_1/","page":"Interprecision Transfers: Part I","title":"Interprecision Transfers: Part I","text":"    N      MV64       LU32       HPS        MPS        LPS   LU32/MPS\n  512    2.8e-05    7.7e-04    5.0e-05    1.0e-04    2.8e-05 7.8e+00\n 1024    1.1e-04    2.6e-03    1.9e-04    7.7e-04    1.0e-04 3.4e+00\n 2048    6.1e-04    1.4e-02    8.8e-04    3.5e-03    4.0e-04 4.0e+00\n 4096    1.9e-03    8.4e-02    4.7e-03    1.4e-02    2.2e-03 5.8e+00\n 8192    6.9e-03    5.9e-01    1.9e-02    5.9e-02    9.7e-03 9.9e+00","category":"page"},{"location":"Details/Interprecision_1/","page":"Interprecision Transfers: Part I","title":"Interprecision Transfers: Part I","text":"The last column of the table is the ratio of timings for the low precision factorization and the mixed precision solve. Keeping in mind that at least two solves will be needed in IR, the table shows that MPS can be a significant fraction of the cost of the solve for smaller problems and that LPS is at least 4 times less costly. This is a compelling case for using LPS in case considered in this section, where high precision is double and low precision is single, provided the performance of IR is equally good.","category":"page"},{"location":"Details/Interprecision_1/","page":"Interprecision Transfers: Part I","title":"Interprecision Transfers: Part I","text":"If one is solving ma vx = vb for multiple right hand sides, as one would do for nonlinear equations in many cases, then LPS is significantly faster for small and moderately large problems. For example, for N=4096 the cost of MPS is roughly 15 of the low precision LU factorization, so if one does more than 6 solves with the same factorization, the solve cost would be more than the factorization cost. LPS is five times faster and we saw this effect while preparing our our nonlinear solver package SIAMFANL.jl. The situation for IR is similar, but one must consider the cost of the high precision matrix-vector multiply, which is about the same as LPS.","category":"page"},{"location":"Details/Interprecision_1/","page":"Interprecision Transfers: Part I","title":"Interprecision Transfers: Part I","text":"We make LPS the default for IR if high precision is double and low precision is single. This decision is good for desktop computing. If low precision is half, then the LPS vs MPS decision needs more scrutiny.","category":"page"},{"location":"Details/Interprecision_1/","page":"Interprecision Transfers: Part I","title":"Interprecision Transfers: Part I","text":"Since MPS does the triangular solves in high precision, one should expect that the results will be more accurate and that the improved accuracy might enable the IR loop to terminate earlier \\cite{CarsonHigham}. We should be able to see that by timing the IR loop after computing the factorization. One should also verify that the residual norms are equally good.","category":"page"},{"location":"Details/Interprecision_1/","page":"Interprecision Transfers: Part I","title":"Interprecision Transfers: Part I","text":"We will conclude this section with two final tables for the results of IR with A = I + alpha G(N). We compare the well conditioned case (alpha=1) and the ill-conditioned case (alpha=800) for a few values of N. We will look at residual and error norms for both approaches to interprecision transfer. The conclusion is that if high precision is double and low is single, the two approaches give equally good results. ","category":"page"},{"location":"Details/Interprecision_1/","page":"Interprecision Transfers: Part I","title":"Interprecision Transfers: Part I","text":"The columns of the tables are the dimensions, the ell^infty relative error norms for both LP and MP interprecision transfers (ELP and EMP) and the corresponding relative residual norms (RLP and RMP).","category":"page"},{"location":"Details/Interprecision_1/","page":"Interprecision Transfers: Part I","title":"Interprecision Transfers: Part I","text":"The results for alpha=1 took 5 IR iterations for all cases. As expected the LPS iteration was faster than MPS. However, for the ill-conditioned alpha=800 case, MPS took one fewer iteration (5 vs 6) than EPS for all but the smallest problem. Even so, the overall solve times were essentially the same.","category":"page"},{"location":"Details/Interprecision_1/","page":"Interprecision Transfers: Part I","title":"Interprecision Transfers: Part I","text":"alpha=1","category":"page"},{"location":"Details/Interprecision_1/","page":"Interprecision Transfers: Part I","title":"Interprecision Transfers: Part I","text":"    N      ELP        EMP        RLP         RMP        TLP       TMP \n  512    4.4e-16    5.6e-16    3.9e-16    3.9e-16    2.8e-04   3.6e-04 \n 1024    6.7e-16    4.4e-16    3.9e-16    3.9e-16    1.2e-03   1.5e-03 \n 2048    5.6e-16    4.4e-16    3.9e-16    3.9e-16    5.8e-03   6.2e-03 \n 4096    1.1e-15    1.1e-15    7.9e-16    7.9e-16    1.9e-02   2.4e-02 \n 8192    8.9e-16    6.7e-16    7.9e-16    5.9e-16    7.0e-02   8.9e-02 ","category":"page"},{"location":"Details/Interprecision_1/","page":"Interprecision Transfers: Part I","title":"Interprecision Transfers: Part I","text":"alpha=800","category":"page"},{"location":"Details/Interprecision_1/","page":"Interprecision Transfers: Part I","title":"Interprecision Transfers: Part I","text":"    N      ELP        EMP        RLP         RMP        TLP       TMP \n  512    6.3e-13    6.2e-13    2.1e-15    1.8e-15    3.3e-04   3.8e-04 \n 1024    9.6e-13    1.1e-12    3.4e-15    4.8e-15    1.3e-03   1.4e-03 \n 2048    1.0e-12    1.2e-12    5.1e-15    4.5e-15    7.2e-03   6.8e-03 \n 4096    2.1e-12    2.1e-12    6.6e-15    7.5e-15    2.4e-02   2.5e-02 \n 8192    3.3e-12    3.2e-12    9.0e-15    1.0e-14    8.4e-02   8.9e-02 ","category":"page"},{"location":"functions/mpgeslir/#mpgeslir:-IR-solver","page":"mpgeslir: IR solver","title":"mpgeslir: IR solver","text":"","category":"section"},{"location":"functions/mpgeslir/#MultiPrecisionArrays.mpgeslir-Tuple{Union{MultiPrecisionArrays.MPHFact, MPLFact}, Any}","page":"mpgeslir: IR solver","title":"MultiPrecisionArrays.mpgeslir","text":"mpgeslir(AF::MPFact, b; reporting=false, verbose=false,           termparms=termparms_default)\n\nI do not export this function. The idea is that you use mplu and do not touch either the constructor or the solver directly.\n\nUse a multi-precision factorization to solve a linear system with plain vanilla iterative refinement.\n\nThis version is analogous to A\\b and combines the factorization and the solve. You start with MPA=MPArray(A) and then pass MPA to mpgeslir and combine the factorization and the solve. \n\nYou can also get the multiprecision factorization directly with\n\nMPF=mplu(A)\n\nand then pass MPF to mpgeslir.\n\nI use this to get some timing results and it's also convenient if you want to do factor and solve in one statement. \n\nYou can also get this with x = MPA\\b.\n\nIf you set the kwarg reporting to true you can get the IR residual history. The output of \n\nx = MPA\\b\n\nUse a multi-precision factorization to solve a linear system with plain vanilla iterative refinement.\n\nMPFact is a union of all the MultiPrecision factorizations in the package.  The triangular solver will dispatch on the various types depending on how the interprecision transfers get done.\n\n\n\n\n\n","category":"method"},{"location":"functions/mpgeslir/#MultiPrecisionArrays.mpgeslir-Tuple{MPArray, Any}","page":"mpgeslir: IR solver","title":"MultiPrecisionArrays.mpgeslir","text":"mpgeslir(MPA::MPArray, b; reporting = false, verbose = false,          termparms=termparms_default)\n\nI do not export this function. The idea is that you use mpglu and do not touch either the constructor or the solver directly.\n\nUse a multi-precision factorization to solve a linear system with plain vanilla iterative refinement.\n\nThis version is analogous to A\\b and combines the factorization and the solve. You start with MPA=MPArray(A) and then pass MPA to mpgeslir and combine the factorization and the solve. \n\nYou can also get the multiprecision factorization directly with\n\nMPF=mplu(A)\n\nand then pass MPF to mpgeslir.\n\nI use this to get some timing results and it's also convenient if you want to do factor and solve in one statement. \n\nYou can also get this with x = MPA\\b.\n\nIf you set the kwarg reporting to true you can get the IR residual history. The output of \n\nx = MPA\\b\n\nor\n\nx=MPF\\b\n\nis the solition. The output of \n\nmout = \\(MPA,b; reporting=true)\n\nor\n\nmout = \\(MPF,b; reporting=true)\n\nis a structure. mpout.sol is the solution. mpout.rhist is the residual history. mpout.dhist is the history of the norms of the corrections.  mpout also contains the datatypes TW for high precision and TF for low precision.\n\nYou may not get exactly the same results for this example on different hardware, BLAS, versions of Julia or this package.  I am still playing with the termination criteria and the iteration count could grow or shrink as I do that.\n\nExample\n\njulia> using MultiPrecisionArrays.Examples\n\n\njulia> N=4096; A = I - 800.0 * Gmat(N); b=ones(N);\njulia> MPF=mplu(A);\n\njulia> mout=\\(MPF, b; reporting=true);\n\njulia> mout.rhist\n7-element Vector{Float64}:\n 1.00000e+00\n 4.24311e-02\n 9.03500e-05\n 9.59277e-08\n 6.12346e-11\n 9.75675e-12\n 8.49343e-12\n\n# Stagnation after six IR iterations\n\njulia> mout.dhist\n6-element Vector{Float64}:\n 2.00420e+02\n 3.15198e-01\n 4.48500e-04\n 4.57912e-07\n 5.88713e-10\n 3.62408e-11\n\n# No correction for the final itertation.\n\njulia> [mout.TW mout.TF]\n1×2 Matrix{DataType}:\n Float64  Float32\n\n\n\n\n\n\n","category":"method"},{"location":"functions/mpkrir/#mpkrir:-Krylov-IR-solver","page":"mpkrir: Krylov-IR solver","title":"mpkrir: Krylov-IR solver","text":"","category":"section"},{"location":"functions/mpkrir/#MultiPrecisionArrays.mpkrir-Tuple{Union{MPBFact, MPGEFact, MultiPrecisionArrays.MPGHFact}, Any}","page":"mpkrir: Krylov-IR solver","title":"MultiPrecisionArrays.mpkrir","text":"mpkrir(AF::MPKFact, b; reporting=false, verbose=false,             mpdebug=false, termparms=termparms_default)\n\nKrylov-IR solver \n\nI do not export this function. The idea is that you use mpglu and do not touch either the constructor or the solver directly.\n\nUse a multi-precision factorization to solve a linear system with IR-Krylov metods\n\nThis is the generic solver used by GMRES-IR and BiCGSTAB-IR. You use the correct MPKFact = Union{MPGFact,MPBFact} structure and mpkrir will do the right thing. \n\nYou should not be calling this directly. Use \\ to solve linear systems with the multiprecision factorization and to  use the optional kwargs.\n\nWe overload the backslash operator to call mpkrir for a multiprecision MPGFact factorization. So if MPA is an MPGArray and  \n\nAF = mpglu!(MPA)\n\nThen AF\\b maps to\n\nmpkrir(AF, b)\n\nwhich does the GMRES-IR solve. You can also get the multiprecision factoriztion directly with\n\nAF = mpglu(A)\n\nwhich builds the mutliprcision MPGArray and then factors the low preicsion copy.\n\nSimilarly if  MPA is an MPBArray. Then\n\nAF = mpblu!(MPA)\n\nThen AF\\b maps to\n\nmpkrir(AF, b)\n\nwhich does the BiCGSTAB-IR solve.\n\nYou can also use the \\ operator to harvest iteration statistics.\n\nYou may not get exactly the same results for this example on different hardware, BLAS, versions of Julia or this package.  I am still playing with the termination criteria and the iteration count could grow or shrink as I do that.\n\nExample\n\n```jldoctest julia> using MultiPrecisionArrays.Examples\n\njulia> N=4096; A = I - 800.0 * Gmat(N); b=ones(N);\n\njulia> AF=mpglu(A);\n\njulia> solout=(AF, b; reporting=true);\n\nCorrect result?\n\njulia> x=solout.sol; norm(b-A*x,Inf) 8.20877e-12\n\nLook at the residual history\n\njulia> solout.rhist\n\n4-element Vector{Float64}:  1.00000e+00  1.25881e-10  8.58902e-12  8.20877e-12\n\nand the correction norm history. No correction for the final iteration.\n\njulia> solout.dhist 3-element Vector{Float64}:  2.00129e+02  1.05241e-10  2.28629e-11\n\nStagnation after the 2nd iteration. Now the Krylovs/iteration\n\njulia> solout.khist 3-element Vector{Int64}:  4  5  5\n\n4-5 Krylovs per iteration.\n\nBiCGSTAB works the same way.\n\n\n\n\n\n","category":"method"},{"location":"Details/Stats/#Harvesting-Iteration-Statistics","page":"Harvesting Iteration Statistics","title":"Harvesting Iteration Statistics","text":"","category":"section"},{"location":"Details/Stats/","page":"Harvesting Iteration Statistics","title":"Harvesting Iteration Statistics","text":"You can get some iteration statistics by using the reporting keyword argument to the solvers. The easiest way to do this is with the backslash command. When you use this option you get a data structure with the solution and the residual history.","category":"page"},{"location":"Details/Stats/","page":"Harvesting Iteration Statistics","title":"Harvesting Iteration Statistics","text":"You may not get exactly the same results for this example on different hardware, BLAS, versions of Julia or this package. I am still playing with the termination criteria and the iteration count could grow or shrink as I do that.","category":"page"},{"location":"Details/Stats/","page":"Harvesting Iteration Statistics","title":"Harvesting Iteration Statistics","text":"julia> using MultiPrecisionArrays\n\njulia> using MultiPrecisionArrays.Examples\n\njulia> N=4096; A = I - Gmat(N); x=ones(N); b=A*x; \n\njulia> MPF=mplu(A);\n\njulia> # Use \\ with reporting=true\n\njulia> mpout=\\(MPF, b; reporting=true);\n\njulia> norm(b-A*mpout.sol, Inf)\n2.22045e-16\n\njulia> # Now look at the residual history\n\njulia> mpout.rhist\n6-element Vector{Float64}:\n 1.00000e+00\n 1.64859e-05\n 1.02649e-10\n 6.35048e-14\n 4.44089e-16\n 2.22045e-16","category":"page"},{"location":"Details/Stats/","page":"Harvesting Iteration Statistics","title":"Harvesting Iteration Statistics","text":"As you can see, IR does well for this problem. The package uses an initial iterate of x = 0 and so the initial residual is simply r = b and the first entry in the residual history is  b _infty. The iteration terminates successfully after five matrix-vector products.","category":"page"},{"location":"Details/Stats/","page":"Harvesting Iteration Statistics","title":"Harvesting Iteration Statistics","text":"You can also look at the norm of the defect.","category":"page"},{"location":"Details/Stats/","page":"Harvesting Iteration Statistics","title":"Harvesting Iteration Statistics","text":"julia> mpout.dhist\n5-element Vector{Float64}:\n 1.00002e+00\n 1.62124e-05\n 1.02649e-10\n 6.35100e-14\n 4.45650e-16","category":"page"},{"location":"Details/Stats/","page":"Harvesting Iteration Statistics","title":"Harvesting Iteration Statistics","text":"You may wonder why the residual after the first iteration was so much larger than single precision roundoff. The reason is that the default  when the low precision is single is to downcast the residual to single before  the solve (onthefly=false). One can enable interprecision transfers on the fly and see the difference.","category":"page"},{"location":"Details/Stats/","page":"Harvesting Iteration Statistics","title":"Harvesting Iteration Statistics","text":"julia> MPF2=mplu(A; onthefly=true);\n\njulia> mpout2=\\(MPF2, b; reporting=true);\n\njulia> mpout2.rhist\n6-element Vector{Float64}:\n 1.00000e+00\n 3.10192e-06\n 1.04403e-11\n 6.13953e-14\n 4.44089e-16\n 2.22045e-16","category":"page"},{"location":"Details/Stats/","page":"Harvesting Iteration Statistics","title":"Harvesting Iteration Statistics","text":"So the second iteration is somewhat better, but the iteration terminated after five iterations in both cases.","category":"page"},{"location":"Details/Stats/","page":"Harvesting Iteration Statistics","title":"Harvesting Iteration Statistics","text":"There are more examples for this in (Kelley, 2024).","category":"page"},{"location":"functions/hlu!/#hlu!:-Get-LU-to-perform-reasonably-well-for-Float16","page":"hlu!: Get LU to perform reasonably well for Float16","title":"hlu!: Get LU to perform reasonably well for Float16","text":"","category":"section"},{"location":"functions/hlu!/#MultiPrecisionArrays.hlu!-Union{Tuple{Matrix{T}}, Tuple{T}} where T","page":"hlu!: Get LU to perform reasonably well for Float16","title":"MultiPrecisionArrays.hlu!","text":"hlu!(A::AbstractMatrix{T}) where {T} Return LU factorization of A\n\nC. T. Kelley, 2023\n\nThis function is a hack of generic_lufact! which is part of\n\nhttps://github.com/JuliaLang/julia/blob/master/stdlib/LinearAlgebra/src/lu.jl\n\nI \"fixed\" the code to be Float16 only and fixed pivoting to only MaxRow.\n\nThe latest version of the original code now lives at \n\nhttps://github.com/JuliaLang/LinearAlgebra.jl/blob/master/src/lu.jl\n\nAll I did in the factorization was thread the critical loop with OhMyThreads:tforeach and put @simd in the inner loop. For larger problems (n >= 1000) these changes got me a 4-15x speedup over Julia's generic lu on my Mac M2 Pro with 8 performance cores. I'm happy.\n\n\n\n\n\n","category":"method"},{"location":"Half_1/#Half-Precision-and-Krylov-IR","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"","category":"section"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"There are two half-precision (16-bit) formats. Julia has native support for IEEE 16-bit floats (Float16). A second format (BFloat16) has a larger exponent field and a smaller  significand (mantissa), thereby trading precision for range. In fact, the exponent field in BFloat is the same size (8 bits) as that for single precision (Float32). The  significand, however, is only 8 bits. Compare this to the size of the exponent fields for  Float16 (5 bits) and single (8 bits). The size of the significand means that you can get in real trouble with half precision in either format.","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"At this point Julia has no native support for BFloat16. Progress is being made and the package BFLoat16s will let you experiment.","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"Using half precision will not speed anything up, in fact it will make  the solver slower. The reason for this is that LAPACK and the BLAS  do not (YET) support half precision, so all the clever stuff in there is missing. We provide a half-precision LU factorization for Float16  /src/Factorizations/hlu!.jl that is better than nothing.  It's a hack of Julia's  generic_lu! with threading ( using  the OhMyThreads threading package and a couple compiler directives. Even so, it's 3–6 x slower than a  double precision LU. Half precision support for both Float16 and BFloat16 is coming  (Julia and Apple support Float16 in hardware! Apple hardware supports BFloat16). However, for now, at least for desktop computing, half precision is for research in iterative refinement, not applications. ","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"Here's a table that illustrates the point. In the table we compare timings for LAPACK's LU to the LU we compute with hlu!.jl. The matrix is  I-8000*G.","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"      N       F64       F32       F16       F16/F64 \n    1024   4.97e-03   2.82e-03   3.51e-02   7.07e+00   \n    2048   2.67e-02   1.49e-02   1.91e-01   7.15e+00   \n    4096   1.64e-01   8.32e-02   7.58e-01   4.63e+00   \n    8192   1.25e+00   7.18e-01   5.67e+00   4.53e+00   ","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"The columns of the table are the dimension of the problem, timings for double, single, and half precision, and the ratio of the half precision timings to double. The timings came from Julia 1.12 - beta 4 running on an Apple M2 Pro with 8 performance cores. ","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"I am constantly playing with hlu!.jl and these timings will almost certainly be different if you try to duplicate them.","category":"page"},{"location":"Half_1/#Half-Precision-is-Subtle","page":"Half Precision and Krylov-IR","title":"Half Precision is Subtle","text":"","category":"section"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"Half precision is also difficult to use properly. The low precision can  make iterative refinement fail because the half precision factorization  can have a large error. Here is an example to illustrate this point.  The matrix here is modestly ill-conditioned and you can see that in the  error from a direct solve in double precision.","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"You may not get exactly the same results for this example on different hardware, BLAS, versions of Julia or this package. I am still playing with the termination criteria and the iteration count could grow or shrink as I do that.","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"julia> A=I - 800.0*G;\n\njulia> x=ones(N);\n\njulia> b=A*x;\n\njulia> xd=A\\b;\n\njulia> norm(b-A*xd,Inf)\n6.96332e-13\n\njulia> norm(xd-x,Inf)\n2.30371e-12","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"Now, if we downcast things to half precision, nothing good happens.","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"julia> AH=Float16.(A);\n\njulia> AHF=hlu!(AH);\n\njulia> z=AHF\\b;\n\njulia> norm(b-A*z,Inf)\n6.25650e-01\n\njulia> norm(z-xd,Inf)\n2.34975e-01","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"So you get very poor, but unsurprising, results. While MultiPrecisionArrays.jl supports half precision and I use it all the time, it is not something you  should use in your own work without looking at the literature and making certain you are prepared for strange results. Getting good results consistently from half precision is an active research area.","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"So, it should not be a surprise that IR also struggles with half precision. We will illustrate this with one simple example. In this example high precision will be single and low will be half. Using {\\bf MPArray} with a single precision matrix will automatically make the low precision matrix half precision.","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"julia> N=4096; G=800.0*Gmat(N); A=I - Float32.(G);\n\njulia> x=ones(Float32,N); b=A*x;\n\njulia> MPF=mplu(A; onthefly=false);\n\njulia> y=MPF\\b;\n\njulia> norm(b - A*y,Inf)\n1.05272e+02","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"So, IR completely failed for this example. We will show how to extract the details of the iteration in a later section.","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"It is also worthwhile to see if doing the triangular solves on-the-fly (MPS) helps. ","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"julia> MPBF=mplu(A);\n\njulia> z=MPBF\\b;\n\njulia> norm(b-A*z,Inf)\n1.28174e-03","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"So, MPS is better in the half precision case. Moreover, it is also less costly thanks to the limited support for half precision computing. For that reason, MPS is the default when high precision is single.","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"However, on-the-fly solves are not enough to get good results and IR still terminates too soon.","category":"page"},{"location":"Half_1/#GMRES-IR","page":"Half Precision and Krylov-IR","title":"GMRES-IR","text":"","category":"section"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"GMRES-IR solves the correction equation with a preconditioned GMRES (Saad and Schultz, 1986) iteration. One way to think of this is that the solve in the IR loop is an approximate solver for the correction equation","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"A d = r","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"where one replaces A with the low precision factors LU. In GMRES-IR one solves the correction equation with a left-preconditioned GMRES iteration using U^-1 L^-1 as the preconditioner. The preconditioned equation is","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"U^-1 L^-1  A d = U^-1 L^-1 r","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"GMRES-IR will not be as efficient as IR because each iteration is itself an GMRES iteration and application of the preconditioned matrix-vector product has the same cost (solve + high precision matrix vector product) as a single IR iteration. However, if low precision is half, this approach can recover the residual norm one would get from a successful IR iteration.","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"There is also a storage problem. One should allocate storage for the Krylov basis vectors and other vectors that GMRES needs internally. We do that in the factorization phase. So the structure MPGEFact has the  factorization of the low precision matrix, the residual, the Krylov basis and some other vectors needed in the solve. ","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"The Julia function mpglu constructs the data structure and factors the low precision copy of the matrix. The output, like that of mplu is a factorization object that you can use with backslash.","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"Here is a well conditioned example. Both IR and GMRES-IR perform well, with GMRES-IR taking significantly more time.  ","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"julia> using MultiPrecisionArrays\n\njulia> using MultiPrecisionArrays.Examples\n\njulia> using BenchmarkTools\n\njulia> N=4069; AD= I - Gmat(N); A=Float32.(AD); x=ones(Float32,N); b=A*x;\n\njulia> MPF=mplu(A); MPF2=mpglu(A);\n\njulia> z=MPF\\b; y=MPF2\\b; println(norm(z-x,Inf),\"  \",norm(y-x,Inf))\n5.9604645e-7  4.7683716e-7\n\njulia> @btime $MPF\\$b;\n  13.582 ms (4 allocations: 24.33 KiB)\n\njulia> @btime $MPF2\\$b;\n  40.344 ms (183 allocations: 90.55 KiB)","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"If you dig into the iterations statistics (more on that later) you will see that the GMRES-IR iteration took almost exactly four times as many solves and residual computations as the simple IR solve.","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"We will repeat this experiment on the ill-conditioned example. In this example, as we saw earlier, IR fails to converge.","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"julia> N=4069; AD= I - 800.0*Gmat(N); A=Float32.(AD); x=ones(Float32,N); b=A*x;\n        \njulia> MPF=mplu(A); MPF2=mpglu(A);\n\njulia> z=MPF\\b; y=MPF2\\b; println(norm(z-x,Inf),\"  \",norm(y-x,Inf))\n0.2875508  0.004160166\n\njulia> println(norm(b-A*z,Inf)/norm(b,Inf),\"  \",norm(b-A*y,Inf)/norm(b,Inf))\n0.0012593127  1.4025759e-5","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"So, the relative error and relative residual norm for GMRES-IR is much smaller than that for IR.","category":"page"},{"location":"Half_1/#BiCGSTAB-IR","page":"Half Precision and Krylov-IR","title":"BiCGSTAB-IR","text":"","category":"section"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"MultiPrecisionArrays.jl also supports BiCGSTAB (der Vorst, 1992). The API is the same as for GMRES-IR with the swap of b for g. So the data structure is MPBArray and the factorizations are mpblu and mpblu!. Keep in mind that a BiCGSTAB iteration costs two matrix-vector and two preconditioner-vector products.","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"We will do the same examples we did for GMRES-IR.","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"julia> using MultiPrecisionArrays\n\njulia> using MultiPrecisionArrays.Examples\n\njulia> using BenchmarkTools\n\njulia> N=4069; AD= I - Gmat(N); A=Float32.(AD); x=ones(Float32,N); b=A*x;\n\njulia> MPFB=mpblu(A); MPF=mplu(A);\n\njulia> z=MPF\\b; y=MPFB\\b; println(norm(z-x,Inf),\"  \",norm(y-x,Inf))\n5.9604645e-7  4.172325e-7\n\njulia> @btime $MPF\\$b;\n  13.371 ms (5 allocations: 24.38 KiB)\n\njulia> @btime $MPFB\\$b;\n  77.605 ms (178 allocations: 821.45 KiB)","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"The only new thing is that the solve for BiCGSAB-IR took roughly twice as long. That is no surprise since the cost of a BiCGSTAB iteration is about double that of a GMRES iteration.","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"The ill-conditioned example tells the same story.","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"julia> N=4069; AD= I - 800.0*Gmat(N); A=Float32.(AD); x=ones(Float32,N); b=A*x;\n\njulia> MPF=mplu(A); MPFB2=mpblu(A);\n\njulia> z=MPF\\b; y=MPFB2\\b; println(norm(z-x,Inf),\"  \",norm(y-x,Inf))\n0.2875508  0.0026364326\n\njulia> println(norm(b-A*z,Inf)/norm(b,Inf),\"  \",norm(b-A*y,Inf)/norm(b,Inf))\n0.0012593127  7.86059e-6","category":"page"},{"location":"Half_1/","page":"Half Precision and Krylov-IR","title":"Half Precision and Krylov-IR","text":"So, as was the case with GMRES, BiCGSTAB-IR is a much better solver that IR alone.","category":"page"},{"location":"functions/MPArray/#MPArray:-constructor","page":"MPArray: constructor","title":"MPArray: constructor","text":"","category":"section"},{"location":"functions/MPArray/#MultiPrecisionArrays.MPArray-Tuple{AbstractMatrix{Float64}}","page":"MPArray: constructor","title":"MultiPrecisionArrays.MPArray","text":"MPArray(AH::AbstractArray{Float64,2}; TF = Float32, onthefly=false) Default constructor for MPArray. \n\nC. T. Kelley 2024\n\nThe MPArray data structure is\n\nstruct MPArray{TW<:AbstractFloat,TF<:AbstractFloat,TR<:AbstractFloat}\n    AH::AbstractArray{TW,2}\n    AL::AbstractArray{TF,2}\n    residual::Vector{TR}\n    sol::Vector{TW}\n    onthefly::Bool\nend\n\nThe constructor just builds an MPArray with TW=Float64. Set TF=Float16 to get double/half IR.\n\n\n\n\n\n","category":"method"},{"location":"functions/MPArray/#MultiPrecisionArrays.MPArray-Tuple{AbstractMatrix{Float32}}","page":"MPArray: constructor","title":"MultiPrecisionArrays.MPArray","text":"MPArray(AH::AbstractArray{Float32,2};               TR = nothing, TF = Float16, onthefly=true) Default single precision constructor for MPArray with TF=Float16\n\nIf your high precision array is single, then your low precision array is half (Duh!). \n\nWe do the triangular solves with on-the-fly interprecision transfer in this case because the bit of extra accuracy makes a difference and, at least for now, on-the-fly interprecision transfers are cheaper.\n\nData structures etc are the same as in the  double-single/half case, but you don't have the option to go lower than half.\n\n\n\n\n\n","category":"method"},{"location":"functions/mpblu!/#mpblu!:-Factor-a-MPBArray-and-set-it-up-for-BiCGSTAB-by-allocating-room-for-a-few-vectors","page":"mpblu!: Factor a MPBArray and set it up for BiCGSTAB by allocating room for a few vectors","title":"mpblu!: Factor a MPBArray and set it up for BiCGSTAB by allocating room for a few vectors","text":"","category":"section"},{"location":"functions/mpblu!/#MultiPrecisionArrays.mpblu!-Tuple{MPBArray}","page":"mpblu!: Factor a MPBArray and set it up for BiCGSTAB by allocating room for a few vectors","title":"MultiPrecisionArrays.mpblu!","text":"mpblu!(MPBA::MPBArray) Factor a MPBArray and set it up for BiCGSTAB-IR\n\nThis function factors the low precision copy and leaves the high precision matrix alone. The constructor for MPBArray allocates storage for the things BiCGSTAB needs.\n\nYou get a factorization object as output and can use \\ to solve linear systems.\n\n\n\n\n\n","category":"method"},{"location":"functions/mpblu!/#MultiPrecisionArrays.mpblu!-Union{Tuple{TW}, Tuple{MPBFact, AbstractMatrix{TW}}} where TW<:Real","page":"mpblu!: Factor a MPBArray and set it up for BiCGSTAB by allocating room for a few vectors","title":"MultiPrecisionArrays.mpblu!","text":"mpblu!(MPG::MPBFact, A::AbstractArray{TW,2}) where TW <: Real Overwrite a multiprecision factorization MPF to reuse the storage to make a multiprecision factorization of a new matrix A.\n\nThis will, of course, trash the original factorization.\n\nTo use this do\n\nMPG=mpblu!(MPF,A)\n\nSimply using\n\nmpblu!(MPF,A) # Don't do this.\n\n(ie without explicitly returning MPG)\n\nmay not do what you want because the multiprecision factorization structure is immutable and MPF.AF.info cannot be changed.\n\nReassigning MPG works and resuses almost all of the storage in the original array.\n\n\n\n\n\n","category":"method"},{"location":"functions/mpglu/#mpglu:-Combine-MPGArray-construction-and-factorization","page":"mpglu: Combine MPGArray construction and factorization","title":"mpglu: Combine MPGArray construction and factorization","text":"","category":"section"},{"location":"functions/mpglu/#MultiPrecisionArrays.mpglu-Union{Tuple{AbstractMatrix{TW}}, Tuple{TW}} where TW<:Real","page":"mpglu: Combine MPGArray construction and factorization","title":"MultiPrecisionArrays.mpglu","text":"mpglu(A::AbstractArray{TW,2}; TF=Float32, TR=nothing,      residterm=residtermdefault1, basissize=10) where TW <: Real\n\nCombines the constructor of the multiprecision GMRES-ready array with the factorization.\n\nStep 1: build the MPGArray\n\n  (a) Store A and b in precision TW.\n\n  (b) Store the factorization (copy of A) in precision TF\n\n  (c) Preallocate storage for the residual, a local copy of the\n  solution, and the Krylov vectors in precision TR\n\nStep 2: Call mpglu! to build the factorization object\n\nThe TR kwarg is the residual precision. Leave this alone unless you know what you are doing. The default is nothing which tells the solver to set TR = TW. If you set TR it must be a higher precision than TW and you are essentially solving TR.(A) x = TR.(b) with IR with the factorization in TF.\n\nThe case of interest here is TW = Float32; TF = Float16; TR = Float64. IR-GMRES with those precisions is sometimes the savior of half precision.\n\nThe default basis size is 10. You can (and should) play with that if you are not happy with the results. If you are having trouble storing enough vectors, IR-BiCGSTAB mpblu is worth a shot.\n\nTake this example, please.\n\nYou may not get exactly the same results for this example on different hardware, BLAS, versions of Julia or this package.  I am still playing with the termination criteria and the iteration count could grow or shrink as I do that.\n\nExample\n\njulia> using MultiPrecisionArrays\n\njulia> using MultiPrecisionArrays.Examples\n\njulia> N=4096; alpha=799.0; AD = I - alpha*Gmat(N); A = Float32.(AD);\n\n# Try vanilla IR with TF=Float16\n\njulia> xe=ones(Float32,N); b=A*xe; AF=mplu(A); \n\njulia> mout=\\(AF, b; reporting=true);\n\njulia> mout.rhist\n4-element Vector{Float64}:\n 9.88750e+01\n 3.92435e+00\n 3.34373e-01\n 2.02045e-01\n\n# That does not look like convergence. What about TR=Float64?\n\njulia> BF=mplu(A; TR=Float64);\n\njulia> mout2=\\(BF, b; reporting=true);\n\njulia> mout2.rhist\n4-element Vector{Float64}:\n 9.88750e+01\n 3.92451e+00\n 3.34292e-01\n 2.02204e-01\n\n# Can Float16 be saved? How 'bout IR-GMRES with a generous basissize.\n# Keep in mind that we terminate on small correction norms\n# in this case, so may well take some extra iterations\n\njulia> GF=mpglu(A; TR=Float64, basissize=20);\n\njulia> mout3=\\(GF, b; reporting=true);\n\njulia> mout3.rhist\n8-element Vector{Float64}:\n 9.88750e+01\n 7.59075e-03\n 1.48842e-05\n 2.17281e-07\n 8.60429e-08\n 7.45077e-08\n 7.91866e-08\n 7.53089e-08\n\n# Shazam! Did we get the solution of the promoted problem?\n\njulia> xp=Float64.(A)\\b; norm(xp-mout3.sol,Inf);\n5.95829e-08\n\n# Yes.\n\n\n\n\n\n\n","category":"method"},{"location":"functions/mplu!/#mplu!:-Simple-MPArray-factorization","page":"mplu!: Simple MPArray factorization","title":"mplu!: Simple MPArray factorization","text":"","category":"section"},{"location":"functions/mplu!/#MultiPrecisionArrays.mplu!-Tuple{MPArray}","page":"mplu!: Simple MPArray factorization","title":"MultiPrecisionArrays.mplu!","text":"mplu!(MPA::MPArray; residterm=residtermdefault)\n\nPlain vanilla MPArray factorization: Factor the low precision copy and leave the high precision matrix alone. You get a factorization object as output and can use \\ to solve linear systems.\n\nThe story on interprecision transfers is that you can set the Boolean onthefly when you construct the MPArray. If you use mplu then you get the defaults\n\nIf onthefly == false then the solver downcasts the residual \n\nbefore the solve and avoids N^2 interprecision transfers.\n\nIf onthefly == true then the solver does interprecision transfers  on the fly and incurs the N^2 interprecision transfer cost for that. \nonthefly == true is what you must use if you plan to use  the low precision  factorization as a preconditioner in IR-GMRES or you're working in  Float16 and the matrix is very ill-conditioned. \nonthefly == nothing means you take the defaults.\n\nThe kwarg residterm sets the termination criterion.  residterm == true (default) terminates the iteration on  small residuals.  residterm == false terminates the iteration on small normwise backward errors. Look at the docs for details.\n\nIf you want to use static arrays with this stuff, import the  mutable @MArray constructor\n\n\n\n\n\n","category":"method"},{"location":"functions/mplu!/#MultiPrecisionArrays.mplu!-Union{Tuple{TW}, Tuple{MPLFact, AbstractMatrix{TW}}} where TW<:Real","page":"mplu!: Simple MPArray factorization","title":"MultiPrecisionArrays.mplu!","text":"mplu!(MPF::MPLFact,A::AbstractArray{TW,2}) where TW <: Real\n\nOverwrite a multiprecision factorization MPF to reuse the storage to make a multiprecision of a new matrix A.\n\nThis will, of course, trash the original factorization.\n\nTo use this do\n\nMPF=mplu!(MPF,A)\n\nSimply using \n\nmplu!(MPF,A) # Don't do this!\n\n(ie without explicitly returning MPF)\n\nmay not do what you want because the multiprecision factorization structure is immutable and MPF.AF.info cannot be changed.\n\nReassigning MPF works and resuses almost all of the storage in the  original array.\n\nIf you want to use static arrays with this stuff, use the  mutable @MArray constructor\n\n\n\n\n\n","category":"method"},{"location":"functions/MPGArray/#MPGArray:-constructor","page":"MPGArray: constructor","title":"MPGArray: constructor","text":"","category":"section"},{"location":"functions/MPGArray/#MultiPrecisionArrays.MPGArray-Tuple{AbstractMatrix{Float64}}","page":"MPGArray: constructor","title":"MultiPrecisionArrays.MPGArray","text":"MPGArray(AH::AbstractArray{Float64,2}; basissize=10, TF=Float32, TR=nothing)\n\nAn MPGArray stores the high precision matrix, the low precision factorization, the Krylov basis, and a few other things GMRES needs. If the high precision matrix is double, the low precision is single by default. Half is an option which you get with TF=Float16.\n\n\n\n\n\n","category":"method"},{"location":"functions/MPGArray/#MultiPrecisionArrays.MPGArray-Tuple{AbstractMatrix{Float32}}","page":"MPGArray: constructor","title":"MultiPrecisionArrays.MPGArray","text":"MPGArray(AH::AbstractArray{Float32,2}; basissize=10, TF=Float16, TR=nothing)\n\nAn MPGArray stores the high precision matrix, the low precision factorization, the Krylov basis, and a few other things GMRES needs. Since High precision is  single, low is half. I'm leaving the kwarg for TF in there because it makes is easier to cut/paste calls to MPGArray different precisions into a CI loop.\n\n\n\n\n\n","category":"method"},{"location":"References/#References","page":"References","title":"References","text":"","category":"section"},{"location":"References/","page":"References","title":"References","text":"Amestoy, P.; Buttari, A.; Higham, N. J.; L’Excellent, J.-Y.; Mary, T. and Vieublé, B. (2024). Five-Precision GMRES-Based Iterative Refinement. SIAM Journal on Matrix Analysis and Applications 45, 529–552.\n\n\n\nDemmel, J.; Hida, Y.; Kahan, W.; Li, X. S.; Mukherjee, S. and Riedy, E. J. (2006). Error Bounds from Extra-Precise Iterative Refinement. ACM Trans. Math. Soft. 13, 325–351.\n\n\n\nHigham, N. J. (1996). Accuracy and Stability of Numerical Algorithms (Society for Industrial and Applied Mathematics, Philadelphia, PA, USA); p. xxviii+688.\n\n\n\nJ.J.Dongarra; C.B.Moler and J.H.Wilkinson (1983). Improving the accuracy of computed eigenvalues and eigenvectors. SIAM Journal on Numerical Analysis 20, 23–45.\n\n\n\nKelley, C. T. (2022). Notebook for Solving Nonlinear Equations with Iterative Methods: Solvers and Examples in Julia, https://github.com/ctkelley/NotebookSIAMFANL. IJulia Notebook.\n\n\n\nKelley, C. T. (2022). SIAMFANLEquations.jl. Julia Package.\n\n\n\nKelley, C. T. (2022). Solving Nonlinear Equations with Iterative Methods: Solvers and Examples in Julia. No. 20 of Fundamentals of Algorithms (SIAM, Philadelphia).\n\n\n\nKelley, C. T. (2024). Interprecision transfers in iterative refinement, arXiv:2407.00827 [math.NA], submitted for publication.\n\n\n\nKelley, C. T. (2024). Using MultiPrecisionArrays.jl: Iterative Refinement in Julia, arXiv:2311.14616 [math.NA].\n\n\n\nKelley, C. T. (2024). MultiPrecisionArrays.jl. Julia Package.\n\n\n\nSaad, Y. and Schultz, M. (1986). GMRES a generalized minimal residual algorithm for solving             nonsymmetric linear systems. SIAM J. Sci. Stat. Comp. 7, 856–869.\n\n\n\nder Vorst, H. A. (1992). Bi-CGSTAB: A fast and smoothly converging variant to Bi-CG for the solution of nonsymmetric systems. SIAM J. Sci. Stat. Comp. 13, 631–644.\n\n\n\nWilkinson, J. H. (1948). Progress Report on the Automatic Computing Engine. Technical Report MA/17/1024 (Mathematics Division, Department of Scientific and Industrial Research, National Physical Laboratory, Teddington, UK).\n\n\n\n","category":"page"},{"location":"functions/mpglu!/#mpglu!:-Factor-a-MPGArray-and-set-it-up-for-GMRES-by-allocating-room-for-Krylov-vectors-etc","page":"mpglu!: Factor a MPGArray and set it up for GMRES by allocating room for Krylov vectors etc","title":"mpglu!: Factor a MPGArray and set it up for GMRES by allocating room for Krylov vectors etc","text":"","category":"section"},{"location":"functions/mpglu!/#MultiPrecisionArrays.mpglu!-Tuple{MPGArray}","page":"mpglu!: Factor a MPGArray and set it up for GMRES by allocating room for Krylov vectors etc","title":"MultiPrecisionArrays.mpglu!","text":"mpglu!(MPGA::MPGArray; residterm=residtermdefault) Factor a MPGArray using the allocations from the structure.\n\nThis function factors the low precision copy and leaves the high precision matrix alone. The constructor  for MPGArray allocates storage for basissize Kylov vectors and some other things GMRES needs. You get a factorization object as output and can use \\ to solve linear systems.\n\nThe kwarg residterm sets the termination criterion.  residterm == true (default) terminates the iteration on  small residuals.  residterm == false terminates the iteration on small normwise backward errors. Look at the docs for details.\n\n\n\n\n\n","category":"method"},{"location":"functions/mpglu!/#MultiPrecisionArrays.mpglu!-Union{Tuple{TW}, Tuple{MPGEFact, AbstractMatrix{TW}}} where TW<:Real","page":"mpglu!: Factor a MPGArray and set it up for GMRES by allocating room for Krylov vectors etc","title":"MultiPrecisionArrays.mpglu!","text":"mpglu!(MPG::MPGEFact, A::AbstractArray{TW,2}) where TW <: Real Overwrite a multiprecision factorization MPF to reuse the storage to make a multiprecision array with a new matrix A.\n\nThis will, of course, trash the original factorization.\n\nTo use this do\n\nMPG=mpglu!(MPG,A)\n\nSimply using\n\nmpglu!(MPG,A) # Don't do this.\n\n(ie without explicitly returning MPG)\n\nmay not do what you want because the multiprecision factorization structure is immutable and MPF.AF.info cannot be changed.\n\nReassigning MPG works and resuses almost all of the storage in the original array\n\n\n\n\n\n","category":"method"},{"location":"Details/Termination/#Terminating-the-while-loop","page":"Terminating the while loop","title":"Terminating the while loop","text":"","category":"section"},{"location":"Details/Termination/","page":"Terminating the while loop","title":"Terminating the while loop","text":"Today's values are","category":"page"},{"location":"Details/Termination/","page":"Terminating the while loop","title":"Terminating the while loop","text":"C_e = 10 C_r = 10 R_max = 5 litmax = 10","category":"page"},{"location":"Details/Termination/","page":"Terminating the while loop","title":"Terminating the while loop","text":"Floating point roundoff is ","category":"page"},{"location":"Details/Termination/","page":"Terminating the while loop","title":"Terminating the while loop","text":"u_w = 05 * eps(TW)","category":"page"},{"location":"Details/Termination/","page":"Terminating the while loop","title":"Terminating the while loop","text":"We can terminate on a small residual","category":"page"},{"location":"Details/Termination/","page":"Terminating the while loop","title":"Terminating the while loop","text":" r   C_r u_w  b ","category":"page"},{"location":"Details/Termination/","page":"Terminating the while loop","title":"Terminating the while loop","text":"or a small relative normwise backward error","category":"page"},{"location":"Details/Termination/","page":"Terminating the while loop","title":"Terminating the while loop","text":" r   C_e u_w ( b  +  A   x )","category":"page"},{"location":"Details/Termination/","page":"Terminating the while loop","title":"Terminating the while loop","text":"Termination on small residual is the default because computing  A  is N^2 work and is more expensive that a few IR iterations. I am using  A _1 because that takes less time (data locality) than   A _infty but it is still a pain. I also compute  A _1 in TF if TF = Float32 or TF = Float64.  Otherwise I use TW.  LAPACK does not support half precision so that's out.","category":"page"},{"location":"Details/Termination/","page":"Terminating the while loop","title":"Terminating the while loop","text":"The problem with these criteria is that IR can stagnate, especially for ill-conditioned problems, before the termination criterion is attained. We detect stagnation by looking for a unacceptable decrease (or increase) in the residual norm. So we will also terminate the iteration if","category":"page"},{"location":"Details/Termination/","page":"Terminating the while loop","title":"Terminating the while loop","text":" r_new  ge R_max  r_old ","category":"page"},{"location":"Details/Termination/","page":"Terminating the while loop","title":"Terminating the while loop","text":"even if the small residual condition is not satisfied. You can also  limit the number of IR iterations to manage stagnation.  Higham [higham97]@cite recomments a limit of litmax = 5. Our default is `litmax = 10, which I may change at any time.","category":"page"},{"location":"Details/Termination/","page":"Terminating the while loop","title":"Terminating the while loop","text":"If TR > TW then I assume you are trying to address extreme ill-coditioning. In that case I terminate when the norm of the correction seems to stagnate. ","category":"page"},{"location":"Details/Termination/","page":"Terminating the while loop","title":"Terminating the while loop","text":"\\| d_{new} \\| \\ge R_{max} \\| d_{old} \\|","category":"page"},{"location":"Details/Termination/","page":"Terminating the while loop","title":"Terminating the while loop","text":"This approach may take one more iteration than the one recommended in (Demmel et al., 2006) but is simpler and will  get you to the theoretical error bould of working precision if u_r = u_w^2.","category":"page"},{"location":"Details/Termination/","page":"Terminating the while loop","title":"Terminating the while loop","text":"I am still playing with the termination criteria and the iteration counts and timings could grow or shrink as I do that. ","category":"page"},{"location":"Details/Termination/","page":"Terminating the while loop","title":"Terminating the while loop","text":"We store the parameters in a TERM structure, which define in the main file for MultiPrecisionArrays.jl.","category":"page"},{"location":"Details/Termination/","page":"Terminating the while loop","title":"Terminating the while loop","text":"struct TERM  \n       Cr::Real\n       Ce::Real\n       Rmax::Real\n       litmax::Int\nend","category":"page"},{"location":"Details/Termination/","page":"Terminating the while loop","title":"Terminating the while loop","text":"We create one TERM structure for the defaults term_parms_default. The solvers take a TERM structure as a kwarg, with term_parms_default as the default.","category":"page"},{"location":"Details/Termination/","page":"Terminating the while loop","title":"Terminating the while loop","text":"To change the parameters use the update_parms function. This function makes a TERM structure for you to pass to the solvers. Herewith the docstrings","category":"page"},{"location":"Details/Termination/","page":"Terminating the while loop","title":"Terminating the while loop","text":"\"\"\"\nupdate_parms(; Cr=Cr_default, Ce=Ce_default,\n      Rmax=Rmax_default, litmax=litmax_default)\n\nC. T. Kelley 2025\n\nUpdate the termination parameters in MultiPrecisionArrays.\n\nThis creates a new TERM data structure that you send to the solver\nas a kwarg.\n\nThis changes the values of the parameters. I do not recommend that\nyou mess with this unless you have a good reason. One such reason\nmight be that the default limit on the number of iterations (10)\nis not working for you.\n\nI start with the default values, so\nunless you specify otherwise, any parameter will take its default value.\n\nWe store the parameters in a mutable structure TERM","category":"page"},{"location":"Details/Termination/","page":"Terminating the while loop","title":"Terminating the while loop","text":"mutable struct TERM        Cr::Real        Ce::Real        Rmax::Real        litmax::Int end","category":"page"},{"location":"Details/Termination/","page":"Terminating the while loop","title":"Terminating the while loop","text":"\nand that is passed to the solvers. So, if AF is a multiprecision\nyou use the optional argument term_parms.\n\n\n\"\"\"\nfunction update_parms(; Cr=Cr_default, Ce=Ce_default,\n      Rmax=Rmax_default, litmax=litmax_default)\nterm_parms=TERM(Cr, Ce, Rmax, litmax)\nreturn term_parms\nend","category":"page"},{"location":"Details/Termination/","page":"Terminating the while loop","title":"Terminating the while loop","text":"Here is an example with the ill-conditioned problem we've been using in other examples. In this example we decrease Rmax and see that the solve takes fewer iterations with no change in the residual quality.","category":"page"},{"location":"Details/Termination/","page":"Terminating the while loop","title":"Terminating the while loop","text":"julia> using MultiPrecisionArrays\n\njulia> using MultiPrecisionArrays.Examples\n\njulia> N=512; A=I - 799.0*Gmat(N); AF=mplu(A);\n\njulia> b=ones(N);\n\njulia> mout=\\(AF,b; reporting=true);\n\n# Termination on a residual norm increase.\n\njulia> mout.rhist\n6-element Vector{Float64}:\n 1.00000e+00\n 4.39096e-03\n 2.85170e-07\n 4.30167e-11\n 6.05982e-12\n 6.34648e-12\n\njulia> term_parms=update_parms(;Rmax=.1);\n\njulia> mout2=\\(AF,b; reporting=true, term_parms=term_parms);\n\n# Termination on minimal decrease in the residual norm.\n\njulia> mout2.rhist\n5-element Vector{Float64}:\n 1.00000e+00\n 4.39096e-03\n 2.85170e-07\n 4.30167e-11\n 6.05982e-12","category":"page"},{"location":"functions/update_parms/#update_parms:-Adjust-termination-criteria-for-while-loop-in-IR","page":"update_parms: Adjust termination criteria for while loop in IR","title":"update_parms: Adjust termination criteria for while loop in IR","text":"","category":"section"},{"location":"functions/update_parms/#MultiPrecisionArrays.update_parms-Tuple{}","page":"update_parms: Adjust termination criteria for while loop in IR","title":"MultiPrecisionArrays.update_parms","text":"updateparms(; Cr=Crdefault, Ce=Cedefault,        Rmax=Rmaxdefault, litmax=litmax_default)\n\nC. T. Kelley 2025\n\nUpdate the termination parameters in MultiPrecisionArrays.\n\nThis creates a new TERM data structure that you send to the solver as a kwarg. \n\nThis changes the values of the parameters. I do not recommend that you mess with this unless you have a good reason. One such reason might be that the default limit on the number of iterations (10) is not working for you.\n\nI start with the default values, so unless you specify otherwise, any parameter will take its default value.\n\nWe store the parameters in a struct TERM\n\nstruct TERM\n       Cr::Real\n       Ce::Real\n       Rmax::Real\n       litmax::Int\nend\n\nand that is passed to the solvers. So, if AF is a multiprecision you use the optional argument term_parms. \n\n\n\n\n\n","category":"method"},{"location":"functions/MPBArray/#MPBArray:-constructor","page":"MPBArray: constructor","title":"MPBArray: constructor","text":"","category":"section"},{"location":"functions/MPBArray/#MultiPrecisionArrays.MPBArray-Tuple{AbstractMatrix{Float64}}","page":"MPBArray: constructor","title":"MultiPrecisionArrays.MPBArray","text":"MPBArray(AH::AbstractArray{Float64,2}; TF=Float32, TR=nothing)\n\nAn MPBArray stores the high precision matrix, the low precision factorization and a few other things BiCGSTAB needs. If the high precision matrix is double, the low precision is single by default. Half is an option which you get with TF=Float16.\n\n\n\n\n\n","category":"method"},{"location":"functions/MPBArray/#MultiPrecisionArrays.MPBArray-Tuple{AbstractMatrix{Float32}}","page":"MPBArray: constructor","title":"MultiPrecisionArrays.MPBArray","text":"MPBArray(AH::AbstractArray{Float32,2}; TF=Float16, TR=nothing)\n\nAn MPBArray stores the high precision matrix, the low precision factorization and a few other things BiCGSTAB needs. Since High precision is  single, low is half. I'm leaving the kwarg for TF in there because it makes is easier to cut/paste calls to MPBArray different precisions into a CI loop.\n\n\n\n\n\n","category":"method"},{"location":"Details/Extended/#Evaluating-residuals-in-higher-precision","page":"Evaluating residuals in higher precision","title":"Evaluating residuals in higher precision","text":"","category":"section"},{"location":"Details/Extended/","page":"Evaluating residuals in higher precision","title":"Evaluating residuals in higher precision","text":"This idea comes from (Wilkinson, 1948) and I am using the notation from (Demmel et al., 2006) and (Amestoy et al., 2024). The idea is to evaluate the residual in a precision TR  higher than the working precision. If you do this, you should store both the solution and the residual in precision TR and to interprecision transfers on the fly. In that case you are really solving a promoted problem (Kelley, 2024)","category":"page"},{"location":"Details/Extended/","page":"Evaluating residuals in higher precision","title":"Evaluating residuals in higher precision","text":"(I_W^R A) x = I_W^R b","category":"page"},{"location":"Details/Extended/","page":"Evaluating residuals in higher precision","title":"Evaluating residuals in higher precision","text":"and, by driving the residual to a small value can mitigate ill-conditioning to some degree. Here I_P^Q is the interprecision transfer from precision P to precision Q. MultiPrecisionArrays   allows you to do this with the multiprecision factorization you get from mplu. ","category":"page"},{"location":"Details/Extended/","page":"Evaluating residuals in higher precision","title":"Evaluating residuals in higher precision","text":"The classic example is to let TR  and TF be single precision and TR be double. The storage penalty is that you must store two copies of A, one for the residual computation and the other for the factorization.","category":"page"},{"location":"Details/Extended/","page":"Evaluating residuals in higher precision","title":"Evaluating residuals in higher precision","text":"Here is an example with a badly conditioned matrix. You must tell mplu to factor in the working precision and use the kwargs in mplu to set TR.","category":"page"},{"location":"Details/Extended/","page":"Evaluating residuals in higher precision","title":"Evaluating residuals in higher precision","text":"You may not get exactly the same results for this example on different hardware, BLAS, versions of Julia or this package. I am still playing with the termination criteria and the iteration count could grow or shrink as I do that.","category":"page"},{"location":"Details/Extended/","page":"Evaluating residuals in higher precision","title":"Evaluating residuals in higher precision","text":"The continuous problem is","category":"page"},{"location":"Details/Extended/","page":"Evaluating residuals in higher precision","title":"Evaluating residuals in higher precision","text":"u - alpha G u = 1 - alpha x (1 - x)2","category":"page"},{"location":"Details/Extended/","page":"Evaluating residuals in higher precision","title":"Evaluating residuals in higher precision","text":"and the solution is u equiv 1. ","category":"page"},{"location":"Details/Extended/","page":"Evaluating residuals in higher precision","title":"Evaluating residuals in higher precision","text":"julia> using MultiPrecisionArrays\n\njulia> using MultiPrecisionArrays.Examples\n\njulia> N=4096; alpha=799.0; AD=I - alpha*Gmat(N);\n\n# conditioning is bad\n\njulia> cond(AD,Inf)\n2.35899e+05\n\n# Set up the single precision computation\n# and use the right side from the integral equation\n\njulia> h=1.0/(N-1); x=collect(0:h:1); bd = 1.0 .- alpha*x.*(1.0 .- x)*.5;\n\n# Solving in double gives the accuracy you'd expect\n\njulia> u=AD\\bd;\n\njulia> norm(u .- 1.0)\n3.16529e-10\n\n# Now move the problem to single precision\n\njulia> A = Float32.(AD); xe=ones(Float32,N); b=Float32.(bd)\n\njulia> # You can see the ill-conditioning\n\njulia> xs = A\\b; norm(xs-xe,Inf)\n1.37073e-02\n\njulia> # The solution of the promoted problem is better.\n\njulia> xp = Float64.(A)\\Float64.(b); norm(xp-xe,Inf)\n1.44238e-04\n\njulia> # Make sure TF is what it needs to be for this example\n\njulia> # Set TR in the call to mplu.\n\njulia> AF = mplu(A; TF=Float32, TR=Float64);\n\njulia> # Use the multiprecision array to solve the problem.\n\njulia> mrout = \\(AF, b; reporting=true);\n\njulia> # look at the residual history\n\njulia> mrout.rhist\n6-element Vector{Float64}:\n 9.88750e+01\n 6.38567e-03\n 1.24560e-06\n 9.55874e-08\n 8.49478e-08\n 8.49478e-08\n\njulia> # Compare the solution to the solution of the promoted problem\n\njulia> norm(mrout.sol - xp,Inf)\n5.95629e-08\n\njulia> # That's consistent with theory.\n\njuila> # So the solution is ok?\n\njulia> norm(mrout.sol - xe, Inf)\n1.44243e-04\n\njulia> # Yes.\n","category":"page"},{"location":"Details/Extended/","page":"Evaluating residuals in higher precision","title":"Evaluating residuals in higher precision","text":"So, is the solution to the promoted problem better than the exact solution I used to build the problem?","category":"page"},{"location":"Details/Extended/","page":"Evaluating residuals in higher precision","title":"Evaluating residuals in higher precision","text":"The reader might try this with TF=Float16, the default when TW = Float32. All that you'll need to do is replace","category":"page"},{"location":"Details/Extended/","page":"Evaluating residuals in higher precision","title":"Evaluating residuals in higher precision","text":"AF = mplu(A; TF=Float32, TR=Float64);","category":"page"},{"location":"Details/Extended/","page":"Evaluating residuals in higher precision","title":"Evaluating residuals in higher precision","text":"with","category":"page"},{"location":"Details/Extended/","page":"Evaluating residuals in higher precision","title":"Evaluating residuals in higher precision","text":"AF = mplu(A; TR=Float64);","category":"page"},{"location":"Details/Extended/","page":"Evaluating residuals in higher precision","title":"Evaluating residuals in higher precision","text":"What goes wrong and why? Fixup to follow.","category":"page"},{"location":"Details/Extended/","page":"Evaluating residuals in higher precision","title":"Evaluating residuals in higher precision","text":"The advantages of evaluating the residual in extended precision grow when A is extremely ill-conditioned. Of course, in this case the factorization in the factorization precision could be so inaccurate that IR will fail to converge. One approach to respond to this, as you might expect, is to use the factorization as a preconditioner and not a solver (Amestoy et al., 2024). We will support this in a later version of MultiPrecisionArrays.jl.","category":"page"},{"location":"Details/Extended/#IR-Krylov-with-high-precision-residuals","page":"Evaluating residuals in higher precision","title":"IR-Krylov with high precision residuals","text":"","category":"section"},{"location":"Details/Extended/","page":"Evaluating residuals in higher precision","title":"Evaluating residuals in higher precision","text":"Half precision factorizations can lead to failure in IR. IR-Krylov methods try to fix this by using the low precision factorization as a preconditioner, not a solver. MultiPrecisionArrays.jl has two IR-Krylov methods and one can adjust the residual precision just as one does with mplu. Here is an example of this using the two  multiprecision IR-Krylov factorizations mpglu (GMRES) and  mpblu (BiCGSTAB).","category":"page"},{"location":"Details/Extended/","page":"Evaluating residuals in higher precision","title":"Evaluating residuals in higher precision","text":"Using the same example, we examine the results.","category":"page"},{"location":"Details/Extended/","page":"Evaluating residuals in higher precision","title":"Evaluating residuals in higher precision","text":"julia> AF = mplu(A; TR=Float64);\n\njulia> mout16=\\(AF, b; reporting=true);\n\njulia> mout16.rhist\n4-element Vector{Float64}:\n 9.88750e+01\n 3.92451e+00\n 3.34292e-01\n 2.02204e-01","category":"page"},{"location":"Details/Extended/","page":"Evaluating residuals in higher precision","title":"Evaluating residuals in higher precision","text":"so plain vanilla IR with TF=Float16, TW=Float32, and TR=Float64 fails to converge. ","category":"page"},{"location":"Details/Extended/","page":"Evaluating residuals in higher precision","title":"Evaluating residuals in higher precision","text":"We support both IR-GMRES and IR-BiCGSTAB for TR > TW. You get this to work just like in {\\tt mplu} by using the keyword argument {\\tt TR}. We will continue with the example in this section and do that. For this example the default basis size of 10 is not enough, so we use 20.","category":"page"},{"location":"Details/Extended/","page":"Evaluating residuals in higher precision","title":"Evaluating residuals in higher precision","text":"julia> GF = mpglu(A; TR=Float64, basissize=20);\n\njulia> moutG = \\(GF, b; reporting=true);\n\njulia> moutG.rhist\n8-element Vector{Float64}:\n 9.88750e+01\n 7.59075e-03\n 1.48842e-05\n 2.17281e-07\n 8.60429e-08\n 7.45077e-08\n 7.91866e-08\n 7.53089e-08\n\njulia> moutG.dhist\n7-element Vector{Float32}:\n 1.03306e+00\n 3.23734e-02\n 2.83073e-04\n 8.92629e-06\n 1.55432e-07\n 6.05685e-08\n 5.96633e-08\n\njulia> xp = Float64.(A)\\b;\n\njulia> norm(xp-moutG.sol, Inf)\n5.95825e-08","category":"page"},{"location":"Details/Extended/","page":"Evaluating residuals in higher precision","title":"Evaluating residuals in higher precision","text":"IR-BiCGSTAB would take fewer iterations than IR-GMRES had we used the default basis size because there's no storage issue. But remember that BiCGSTAB has a higher cost per linear iteration.","category":"page"},{"location":"Details/Extended/","page":"Evaluating residuals in higher precision","title":"Evaluating residuals in higher precision","text":"julia> BF = mpblu(A; TR=Float64);\n\njulia> moutB = \\(BF, b; reporting=true);\n\njulia> moutB.rhist\n5-element Vector{Float64}:\n 9.88750e+01\n 1.86437e-07\n 7.53089e-08\n 7.53089e-08\n 7.53089e-08\n\njulia> moutB.dhist\n4-element Vector{Float32}:\n 1.00227e+00\n 2.05457e-06\n 5.95821e-08\n 5.95821e-08\n\njulia> norm(xp - moutB.sol, Inf)\n5.95825e-08","category":"page"},{"location":"functions/mpblu/#mpblu:-Combine-MPBArray-construction-and-factorization","page":"mpblu: Combine MPBArray construction and factorization","title":"mpblu: Combine MPBArray construction and factorization","text":"","category":"section"},{"location":"functions/mpblu/#MultiPrecisionArrays.mpblu-Union{Tuple{AbstractMatrix{TW}}, Tuple{TW}} where TW<:Real","page":"mpblu: Combine MPBArray construction and factorization","title":"MultiPrecisionArrays.mpblu","text":"mpblu(A::AbstractArray{TW,2}; TF=Float32, TR=nothing, i           residterm=residtermdefault) where TW <: Real\n\nCombines the constructor of the multiprecision BiCGSTAB-ready array with the factorization.\n\nStep 1: build the MPBArray\n\nStep 2: Call mpblu! to build the factorization object\n\nStep 3: Allocate the internal vectors that BiCGSTAB needs.\n\nIR-Krylov methods were designed as saviors of half precision. So, as we did with mpglu, we will run through some examples. The difference here is that there is no Kylov basis to store. \n\nHere's the example from mpglu\n\nYou may not get exactly the same results for this example on different hardware, BLAS, versions of Julia or this package.  I am still playing with the termination criteria and the iteration count could grow or shrink as I do that.\n\n#Example\n\njulia> using MultiPrecisionArrays\n\njulia> using MultiPrecisionArrays.Examples\n\njulia> N=4096; alpha=799.0; AD = I - alpha*Gmat(N); A = Float32.(AD);\n\n# Try vanilla IR with TF=Float16\n\njulia> xe=ones(Float32,N); b=A*xe; AF=mplu(A);\n\njulia> mout=\\(AF, b; reporting=true);\n\njulia> mout.rhist\n5-element Vector{Float64}:\n 9.88750e+01\n 3.92435e+00\n 3.34373e-01\n 2.02045e-01\n 2.24720e-01\n\n# That does not look like convergence. What about TR=Float64?\n\njulia> BF=mplu(A; TR=Float64);\n\njulia> mout2=\\(BF, b; reporting=true);\n\njulia> mout2.rhist\n5-element Vector{Float64}:\n 9.88750e+01\n 3.92614e+00\n 3.34301e-01\n 2.01975e-01\n 2.24576e-01\n\n# This is where we were in the docs for ```mpglu```. I'll try IR-BiCGSTAB\n\njulia> GF=mpblu(A; TR=Float64);\n\njulia> mout3=\\(GF, b; reporting=true);\n\njulia> mout3.rhist\n4-element Vector{Float64}:\n 9.88750e+01\n 2.16858e-11\n 8.38440e-13\n 8.81073e-13\n\n# That is very different from IR-GMRES. The reason is that there is no\n# limit on Krylov iterations because there is no Krylov subspace.\n# So, the linear work produces a large reduction in the residual in\n# the first iterate.\n\n# Of course, we got it right and solved the promoted problem.\n\njulia> xp=Float64.(A)\\b; norm(xp-mout3.sol,Inf)\n1.63376e-11\n\n\n\n\n\n","category":"method"},{"location":"#multiprecisionarrays.jl-v0.1.5","page":"Home","title":"multiprecisionarrays.jl v0.1.5","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"C. T. Kelley","category":"page"},{"location":"","page":"Home","title":"Home","text":"MultiPrecisionArrays.jl  (Kelley, 2024) is a package for iterative refinement. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"These docs are enough to get you started. The complete version with a better account of the theory is (Kelley, 2024). ","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package uses SIAMFANLEquations.jl (Kelley, 2022), the solver package associated with a book (Kelley, 2022) and suite of IJulia notebooks (Kelley, 2022).","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package provides data structures and solvers for several variants of iterative refinement (IR). It will become much more useful when half precision (aka Float16) is fully supported in LAPACK/BLAS. For now, it's only general-purpose application is classical iterative refinement with double precision equations and single precision factorizations.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The half precision stuff is good for those of us doing research in this field. Half precision performance has progressed to the point where you can actually get things done. On an Apple M2-Pro, a half precision LU only costs 3–5 times what a double precision LU costs. This may be as good as it gets unless someone wants to duplicate the LAPACK implementation and get the benefits from blocking, recursion, and clever cache management.","category":"page"},{"location":"","page":"Home","title":"Home","text":"We use a hack-job LU factorization for half precision. Look at the source for hlu!.jl.","category":"page"},{"location":"#What-is-iterative-refinement.","page":"Home","title":"What is iterative refinement.","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The idea is to solve Ax=b in high precision (the working precision) TW with a factorization in lower precision (the factorization precision) TF and a residual computed in precision (the residual precision) TR.","category":"page"},{"location":"","page":"Home","title":"Home","text":"In the case where the working precision and the residual precision are the same, one can view IR as  a perfect example of a storage/time tradeoff. To solve a linear system   Ax=b with IR, one incurs the storage penalty of making a low  precision copy of  and reaps the benefit of only having to factor the  low precision copy.","category":"page"},{"location":"","page":"Home","title":"Home","text":"IR is also used to address very poor conitioning. IR was invented (Wilkinson, 1948) with this in mind. Here one stores and factors A in one precision but evaluates the residual in a higher precision.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Here is the textbook  version (Higham, 1996) using the LU factorization.","category":"page"},{"location":"","page":"Home","title":"Home","text":"IR(A, b)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Initialize: x = 0,  r = b\nFactor A = LU in a lower precision\nWhile  r  is too large\nCompute the defect (correction) d = (LU)^-1 r\nCorrect the solution x = x + d\nUpdate the residual r = b - Ax\nend","category":"page"},{"location":"","page":"Home","title":"Home","text":"In Julia, a code to do this would solve the linear system A x = b in double precision by using a factorization in a lower precision, say single, within a residual correction iteration. This means that one would need to allocate storage for a copy of A is the lower precision and factor that copy. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"Then one has to determine what the line d = (LU)^-1 r means. Do you cast r into the lower precision before the solve or not? MultiPrecisionArrays.jl provides data structures and solvers to manage this. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"Here's a simple Julia function for IR that","category":"page"},{"location":"","page":"Home","title":"Home","text":"\"\"\"\nIR(A,b)\nSimple minded iterative refinement\nSolve Ax=b\n\"\"\"\nfunction IR(A, b)\n    x = zeros(length(b))\n    r = copy(b)\n    tol = 100.0 * eps(Float64)\n    #\n    # Allocate a single precision copy of A and factor in place\n    #\n    A32 = Float32.(A)\n    AF = lu!(A32)\n    #\n    # Give IR at most ten iterations, which it should not need\n    # in this case\n    #\n    itcount = 0\n    # The while loop will get more attention later.\n    while (norm(r) > tol * norm(b)) && (itcount < 10)\n        #\n        # Store r and d = AF\\r in the same place.\n        #\n        ldiv!(AF, r)\n        x .+= r\n        r .= b - A * x\n        itcount += 1\n    end\n    return x\nend","category":"page"},{"location":"","page":"Home","title":"Home","text":"As written in the function, the computation of the defect uses ldiv! to compute AF\\r. This means that the two triangular factors are stored in single precision and interprecision transfers are done with each step in the factorization. While that on the fly interprecision  transfer is an option, and is needed in many situations, the default is to downcast r to low precision, do the solve entirely in low precision, and the upcast the result. The code for that looks like","category":"page"},{"location":"","page":"Home","title":"Home","text":"normr=norm(r)\nds=Float32.(r/normr)\nldiv!(AF, ds)\nr .= Float64.(ds)*normr","category":"page"},{"location":"","page":"Home","title":"Home","text":"The scaling by 1.0/normr helps to avoid underflow, which is most important when the low precision is Float16. We will discuss interprecision  transfer costs later.","category":"page"},{"location":"#Integral-Equations-Example","page":"Home","title":"Integral Equations Example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The submodule MultiPrecisionArrays.Examples has an example which we will  use for most of the documentation. The function Gmat(N) returns the trapezoid rule discretization of the Greens operator  for -d^2dx^2 on 01 with homogeneous Dirichlet boundary conditions.","category":"page"},{"location":"","page":"Home","title":"Home","text":"G u(x) = int_0^1 g(xy) u(y)  dy ","category":"page"},{"location":"","page":"Home","title":"Home","text":"where","category":"page"},{"location":"","page":"Home","title":"Home","text":"g(xy) = \n    leftbeginarrayc\n        y (1-x)   x  y\n        x (1-y)   x le y\n    endarrayright","category":"page"},{"location":"","page":"Home","title":"Home","text":"The eigenvalues of G are 1(n^2 pi^2) for n = 1 2 dots.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The code for this is in the /src/Examples directory.  The file is Gmat.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"In the example we will build a matrix A = I - alpha G. In the examples we will use alpha=10, a very well conditioned case, and alpha=8000 This latter case is very near singularity.","category":"page"},{"location":"","page":"Home","title":"Home","text":"We will solve a linear system with both double precision LU and an MPArray and compare execution time and the quality of the results.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The example below compares the cost of a double precision factorization to a MPArray factorization. The MPArray structure has a high precision and a low precision matrix. The structure we will start with  is","category":"page"},{"location":"","page":"Home","title":"Home","text":"struct MPArray{TW<:AbstractFloat,TF<:AbstractFloat,TR<:AbstractFloat}\n    AH::AbstractArray{TW,2}\n    AL::AbstractArray{TF,2}\n    residual::Vector{TR}\n    sol::Vector{TR}\n    onthefly::Bool\nend","category":"page"},{"location":"","page":"Home","title":"Home","text":"The structure also stores the residual and a local copy of the solution in precisoin TR. Typically TR = TW. The onthefly Boolean tells the solver how to do the interprecision transfers. The easy way to get started is to use the mplu  command directly on the matrix. That will build the MPArray, follow that with the factorization, and put in all in a structure that you can use with \\.","category":"page"},{"location":"","page":"Home","title":"Home","text":"While we document MPArray and other multiprecision data structures, we do not export the constructors. You should use the multiprecision factorizations instead.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Now we will see how the results look. In this example we compare the result with iterative refinement with A\\b, which is LAPACK's LU.  As you can see the results are equally good. Note that the factorization object MPF is the output of mplu. This is analogous to AF=lu(A) in LAPACK.","category":"page"},{"location":"","page":"Home","title":"Home","text":"You may not get exactly the same results for the examples on different hardware, BLAS, versions of Julia or this package.  I am still playing with the termination criteria and the iteration count could grow or shrink as I do that.","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> using MultiPrecisionArrays\n\njulia> using MultiPrecisionArrays.Examples\n\njulia> using BenchmarkTools\n\njulia> N=4096;\n\njulia> G=Gmat(N);\n\njulia> A = I - G;\n\njulia> MPF=mplu(A); AF=lu(A);\n\njulia> z=MPF\\b; w=AF\\b;\n\njulia> ze=norm(z-x,Inf); zr=norm(b-A*z,Inf)/norm(b,Inf);\n\njulia> we=norm(w-x,Inf); wr=norm(b-A*w,Inf)/norm(b,Inf);\n\njulia> println(\"Errors: $ze, $we. Residuals: $zr, $wr\")\nErrors: 5.55112e-16, 6.68354e-14. Residuals: 6.66134e-16, 6.68354e-14\n","category":"page"},{"location":"","page":"Home","title":"Home","text":"So the results are equally good.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The compute time for mplu should be a bit more than half that of lu!. The reason is that mplu factors a low precision array, so the factorization cost is cut in half. Memory is a different story. The reason is that both mplu and lu! do not allocate storage for a new high precision array, but mplu allocates for a low precision copy, so the memory and allocation cost for mplu is 50%  more than lu. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> @belapsed mplu($A)\n8.60945e-02\n\njulia> @belapsed lu!(AC) setup=(AC=copy($A))\n1.42840e-01\n\n# And now for the solve times.\n\njulia> @belapsed ldiv!($AF,bb) setup=(bb = copy($b))\n4.79117e-03\n\njulia> @belapsed $MPF\\$b\n2.01195e-02","category":"page"},{"location":"","page":"Home","title":"Home","text":"So the total solve time is less, but the O(N^2) work is not zero.","category":"page"},{"location":"","page":"Home","title":"Home","text":"It is no surprise that the factorization in single precision took roughly half as long as the one in double. In the double-single precision case, iterative refinement is a great example of a time/storage tradeoff. You have to store a low precision copy of A, so the storage burden increases by 50% and the factorization time is cut in half. The advantages of IR increase as the dimension increases. IR is less impressive for smaller problems and can even be slower","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> N=30; A=I + Gmat(N); \n\njulia> @belapsed mplu($A)\n5.22217e-06\n\njulia> @belapsed lu!(AC) setup=(AC=copy($A))\n3.70825e-06","category":"page"},{"location":"#Options-and-data-structures-for-mplu","page":"Home","title":"Options and data structures for mplu","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Here is the source for mplu","category":"page"},{"location":"","page":"Home","title":"Home","text":"\"\"\"\nmplu(A::AbstractArray{Float64,2}; TF=Float32, onthefly=false)\n\nCombines the constructor of the multiprecision array with the\nfactorization. \n\"\"\"\nfunction mplu(A::AbstractArray{TW,2}; TF=Float32, onthefly=nothing) where TW <: Real\n#\n# If the high precision matrix is single, the low precision must be half.\n#\n(TW == Float32) && (TF = Float16)\n#\n# Unless you tell me otherwise, onthefly is true if TF is half\n# and false if TF is single.\n#\n(onthefly == nothing ) && (onthefly = (TF==Float16))\nMPA=MPArray(A; TF=TF, onthefly=onthefly)\nMPF=mplu!(MPA)\nreturn MPF\nend","category":"page"},{"location":"","page":"Home","title":"Home","text":"The function mplu has two keyword arguments. The easy one to understand is TF which is the precision of the factorization. Julia has support for single (Float32) and half (Float16) precisions. If you set TF=Float16 then low precision will be half. Don't do that unless you know what you're doing. Using half precision is a good way to get incorrect results. Look at the section on half precision in this Readme for a bit more bad news.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The other keyword argument is onthefly. That keyword controls how the triangular solvers from the factorization work. When you solve","category":"page"},{"location":"","page":"Home","title":"Home","text":"LU d = r","category":"page"},{"location":"","page":"Home","title":"Home","text":"The LU factors are in low precision and the residual r is in high precision. If you let Julia and LAPACK figure out what to do, then the solves will be done in high precision and the entries in the LU factors will be converted to high precision with each binary operation. The output d will be in high precision. This is called interprecision transfer on-the-fly and onthefly = true will tell the solvers to do it that way. You have N^2 interprecision transfers with each solve and, as we will see, that can have a non-trivial cost.","category":"page"},{"location":"","page":"Home","title":"Home","text":"When low precision is Float32, then the default is (onthefly = false). This converts r to low precision, does the solve entirely in low precision, and then promotes d to high precision. You need to be careful to avoid overflow and, more importantly, underflow when you do that and we scale r to be a unit vector before conversion to low precision and reverse the scaling when we promote d. We take care of this for you.","category":"page"},{"location":"","page":"Home","title":"Home","text":"mplu calls the constructor (MPArray) for the multiprecision array. The constructor allocates storage for a low precision copy of A and then factors the low precision matrix. In some cases, such as nonlinear solvers, you will want to separate the constructor and the factorization. When you do that remember that mplu! overwrites the low precision copy of A with the factors. The factorization object is different from the multiprecision array, even though they share storage. This is just like lu!.","category":"page"},{"location":"#Memory-Allocations-for-mplu","page":"Home","title":"Memory Allocations for mplu","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The memory footprint of a multiprecision array is dominated by the high precision array and the low precision copy. The allocations of","category":"page"},{"location":"","page":"Home","title":"Home","text":"AF1=lu(A)","category":"page"},{"location":"","page":"Home","title":"Home","text":"and","category":"page"},{"location":"","page":"Home","title":"Home","text":"AF2=mplu(A)","category":"page"},{"location":"","page":"Home","title":"Home","text":"are very different. Typically lu makes a high precision copy of A and factors that with lu!. mplu on the other hand, uses A as the high precision matrix in the multiprecision array structure and the makes a low precision copy to send to lu!. Hence mplu has half the allocation burden of lu.","category":"page"},{"location":"","page":"Home","title":"Home","text":"That is, of course misleading. The memory-efficient  way to apply lu is to overwrite A with the factorization using","category":"page"},{"location":"","page":"Home","title":"Home","text":"AF1=lu!(A).","category":"page"},{"location":"","page":"Home","title":"Home","text":"mplu uses an analog of this approach internally. mplu first builds an MPArray structure with","category":"page"},{"location":"","page":"Home","title":"Home","text":"MPA = MPArray(A)","category":"page"},{"location":"","page":"Home","title":"Home","text":"which makes A the high precision matrix and also makes a low precision copy. This is the stage where the extra memory is allocated for the the low precision copy. Then mplu computes the factorization of the low precision matrix with mplu! to construct the factorization object.","category":"page"},{"location":"","page":"Home","title":"Home","text":"MPF = mplu!(MPA).","category":"page"},{"location":"","page":"Home","title":"Home","text":"So, the function mplu simply applies MPArray and follows that  with mplu!. ","category":"page"},{"location":"#Other-IR-software-in-Julia","page":"Home","title":"Other IR software in Julia","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The package IterativeRefinement.jl is an implementation of the IR method from (J.J.Dongarra et al., 1983).","category":"page"},{"location":"","page":"Home","title":"Home","text":"The unregistered package Itref.jl implements IR and the GMRES-IR method from  (Amestoy et al., 2024) and was used to obtain the numerical results in that paper. It does not provide the data structures for preallocation that we do and does not seem to have been updated lately.","category":"page"},{"location":"Details/N2Work/#Is-O(N2)-work-negligible?","page":"Is O(N^2) work negligible?","title":"Is O(N^2) work negligible?","text":"","category":"section"},{"location":"Details/N2Work/","page":"Is O(N^2) work negligible?","title":"Is O(N^2) work negligible?","text":"In this section TR = TW = Float64 and TF = TS = Float32, which means that the interprecision transfers in the triangular solvers are done in-place. We terminate on small residuals.","category":"page"},{"location":"Details/N2Work/","page":"Is O(N^2) work negligible?","title":"Is O(N^2) work negligible?","text":"The premise behind IR is that reducing the O(N^3) cost of the factorization will make the solve faster because everything else is O(N^2) work. It's worth looking into this.","category":"page"},{"location":"Details/N2Work/","page":"Is O(N^2) work negligible?","title":"Is O(N^2) work negligible?","text":"We will use the old-fashioned definition of a FLOP as an add, a multiply and a bit of address computation. So we have N^2 flops for any of","category":"page"},{"location":"Details/N2Work/","page":"Is O(N^2) work negligible?","title":"Is O(N^2) work negligible?","text":"matrix-vector multiply A x,\nthe two triangular solves with the LU factors (LU)^-1 b, and\ncomputation of the ell^1 or ell^infty matrix operator norms  A _1infty.","category":"page"},{"location":"Details/N2Work/","page":"Is O(N^2) work negligible?","title":"Is O(N^2) work negligible?","text":"A linear solve with an LU factorization and the standard triangular solve has a cost of (N^33) + N^2 TR-FLOPS. The factorization for IR has a cost of N^33 TF-FLOPS or N^36 TR-FLOPS.","category":"page"},{"location":"Details/N2Work/","page":"Is O(N^2) work negligible?","title":"Is O(N^2) work negligible?","text":"A single IR iteration costs a matrix-vector product in precision TR and a triangular solve in precision TF for a total of 3 N^22 TR-FLOPS. Hence a linear solve with IR that needs n_I iterations costs","category":"page"},{"location":"Details/N2Work/","page":"Is O(N^2) work negligible?","title":"Is O(N^2) work negligible?","text":"fracN^36 + 3 n_I N^22","category":"page"},{"location":"Details/N2Work/","page":"Is O(N^2) work negligible?","title":"Is O(N^2) work negligible?","text":"TR-FLOPS if one terminates on small residuals and an extra N^2 TR-FLOPS if one computes the norm of ma in precision TR.","category":"page"},{"location":"Details/N2Work/","page":"Is O(N^2) work negligible?","title":"Is O(N^2) work negligible?","text":"IR will clearly be better for large values of N. How large is that? In this example we compare the cost of factorization and solve using lu! and ldiv (cols 2-4) with the equivalent multiprecision commands mplu and backslash","category":"page"},{"location":"Details/N2Work/","page":"Is O(N^2) work negligible?","title":"Is O(N^2) work negligible?","text":"The operator is A = I - Gmat(N). We tabulate","category":"page"},{"location":"Details/N2Work/","page":"Is O(N^2) work negligible?","title":"Is O(N^2) work negligible?","text":"LU: time for AF=lu!(A)\nTS: time for ldiv!(AF,b)\nTOTL = LU+TS\nMPLU: time for MPF=mplu(A)\nMPS: time for MPF\\b\nTOT: MPLU+MPS\nOPNORM: Cost for  A _1, which one needs to terminate on small normwise backward error.","category":"page"},{"location":"Details/N2Work/","page":"Is O(N^2) work negligible?","title":"Is O(N^2) work negligible?","text":"The message from the tables is that the triangular solves are more costly than operation counts might indicate. One reason for this is that the LU factorization exploits multi-core computing better than a triangular solve. It is also interesting to see how the choice of BLAS affects the results and how the cost of the operator norm of the matrix is more than a triangular solve.","category":"page"},{"location":"Details/N2Work/","page":"Is O(N^2) work negligible?","title":"Is O(N^2) work negligible?","text":"For both cases, multiprecision arrays perform better when N ge 2048 with the difference becoming larger as N increases.","category":"page"},{"location":"Details/N2Work/","page":"Is O(N^2) work negligible?","title":"Is O(N^2) work negligible?","text":"openBLAS","category":"page"},{"location":"Details/N2Work/","page":"Is O(N^2) work negligible?","title":"Is O(N^2) work negligible?","text":"   N        LU        TS       TOTL      MPLU       MPS       TOT    OPNORM  \n   512  9.87e-04  5.35e-05  1.04e-03  7.74e-04  2.90e-04  1.06e-03  1.65e-04 \n  1024  3.67e-03  2.14e-04  3.88e-03  3.21e-03  8.83e-04  4.10e-03  7.80e-04 \n  2048  2.10e-02  1.20e-03  2.22e-02  1.54e-02  4.72e-03  2.02e-02  3.36e-03 \n  4096  1.46e-01  5.38e-03  1.51e-01  8.93e-02  1.91e-02  1.08e-01  1.43e-02 \n  8192  1.10e+00  2.01e-02  1.12e+00  5.98e-01  6.89e-02  6.67e-01  5.83e-02 ","category":"page"},{"location":"Details/N2Work/","page":"Is O(N^2) work negligible?","title":"Is O(N^2) work negligible?","text":"AppleAccelerateBLAS","category":"page"},{"location":"Details/N2Work/","page":"Is O(N^2) work negligible?","title":"Is O(N^2) work negligible?","text":"   N        LU        TS       TOTL      MPLU       MPS       TOT    OPNORM  \n   512  7.86e-04  1.10e-04  8.96e-04  4.76e-04  3.58e-04  8.35e-04  1.65e-04 \n  1024  3.28e-03  4.54e-04  3.73e-03  2.44e-03  1.30e-03  3.74e-03  7.80e-04 \n  2048  2.27e-02  2.46e-03  2.52e-02  1.32e-02  1.13e-02  2.45e-02  3.36e-03 \n  4096  1.52e-01  1.13e-02  1.63e-01  6.51e-02  5.62e-02  1.21e-01  1.40e-02 \n  8192  1.17e+00  5.35e-02  1.23e+00  6.27e-01  2.48e-01  8.75e-01  5.67e-02 ","category":"page"},{"location":"functions/mplu/#mplu:-Combine-MPArray-construction-and-factorization","page":"mplu: Combine MPArray construction and factorization","title":"mplu: Combine MPArray construction and factorization","text":"","category":"section"},{"location":"functions/mplu/#MultiPrecisionArrays.mplu-Union{Tuple{AbstractMatrix{TW}}, Tuple{TW}} where TW<:Real","page":"mplu: Combine MPArray construction and factorization","title":"MultiPrecisionArrays.mplu","text":"mplu(A::AbstractArray{TW,2}; TF=nothing, TR=nothing, residterm=residtermdefault,                     onthefly=nothing) where TW <: Real\n\nCombines the constructor of the multiprecision array with the factorization. \n\nStep 1: build the MPArray. \n\n  (a) Store A and b in precision TW. \n\n  (b) Store the factorization (copy of A) in precision TF\n\n  (c) Preallocate storage for the residual and a local copy of the\n  solution in precision TR\n\nStep 2: factor the low precision copy and return the factorization object\n\nThe TR kwarg is the residual precision. Leave this alone unless you know what you are doing. The default is nothing which tells the solver to set TR = TW. If you set TR it must be a higher precision than TW and you are essentially solving TR.(A) x = TR.(b) with IR with the factorization in TF. The MPArray structure stores the solution and the residual in precision TR and so the residual computation is done via TR.(A) x. The interprecision transfers are on the fly. So, the storage cost is the matrix, and the copy in the factorization precision.\n\nThe classic case is TW = TF = Float32 and TR = Float64. The nasty part of this is that you must store TWO copies of the matrix. One for the residual computation and the other to overwrite with the factors. I do not think this is a good deal unless A is seriously ill-conditioned. My support for this is through mplu. To do this you must put the TR kwarg explicitly in your call to mplu.   \n\nThe kwarg residterm sets the termination criterion. residterm == true (default) terminates the iteration on small residuals.  residterm == false terminates the iteration on small normwise backward errors. Look at the docs for details.\n\nYou may not get exactly the same results for this example on different hardware, BLAS, versions of Julia or this package.  I am still playing with the termination criteria and the iteration count could grow or shrink as I do that.\n\nExample\n\njulia> using MultiPrecisionArrays.Examples\n\njulia> n=31; alpha=Float32(1.0);\n\njulia> G=Gmat(n, Float32);\n\njulia> A = I + alpha*G;\n\njulia> b = A*ones(Float32,n);\n\n# use mpa with TF=TW=Float32 and TR=Float64\n\njulia> AF = mplu(A; TF=Float32, TR=Float64, onthefly=true);\n\n# Solve and save the iteration history. Set the kwarg reporting\n# to true and get iteration statistics. Look at the docs for\n# details.\n\njulia> mout = \\(AF, b; reporting=true);\n\njulia> mout.rhist\n3-element Vector{Float64}:\n 1.12500e+00\n 2.66437e-07\n 5.61655e-08\n\n# What does this mean. I'll solve the promoted problem. TR.(A) x = b\n\njulia> AD=Float64.(A);\n\njulia> xd = AD\\b;\n\njulia> norm(xd - mout.sol,Inf)\n5.62965e-08\n\n# So IR with TR > TW solves a promoted problem to TW roundoff.\n\n\n\n\n\n","category":"method"}]
}
